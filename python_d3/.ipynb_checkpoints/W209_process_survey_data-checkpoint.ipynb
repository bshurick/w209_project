{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data from Duke University and GfK's \"Measuring Morality\" project \n",
    "\n",
    "- **Goal**: Place data in format for interactive visualizations in D3.js\n",
    "\n",
    "- **Dataset Source:** http://kenan.ethics.duke.edu/attitudes/resources/measuring-morality/\n",
    "- **Codebook Source:** http://kenan.ethics.duke.edu/attitudes/files/2012/08/KN-Morality-Survey-Technical-Report.pdf\n",
    "\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Explore and Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /Users/dschan/Downloads/UCB-MIDS-W209/Interactive/MMdata_merged.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9b5e0d449bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# read csv data as pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/dschan/Downloads/UCB-MIDS-W209/Interactive/MMdata_merged.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# check data type and shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dschan/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dschan/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dschan/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dschan/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dschan/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /Users/dschan/Downloads/UCB-MIDS-W209/Interactive/MMdata_merged.csv does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# read csv data as pandas dataframe\n",
    "\n",
    "d = pd.read_csv('/Users/dschan/Downloads/UCB-MIDS-W209/Interactive/MMdata_merged.csv')\n",
    "\n",
    "# check data type and shape\n",
    "\n",
    "print type(d)\n",
    "print \"shape:\", d.shape[0]\n",
    "print\n",
    "\n",
    "# select specific columns: weight column, demographic columns, and moral-related columns\n",
    "\n",
    "d = d[[ 'weight',\n",
    "        'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', 'PPSTATEN',\n",
    "        'DPES11',\n",
    "        'EPQ1',\n",
    "        'I10',\n",
    "        'IS1','IS6','IS8',\n",
    "        'L1','L4','L9','L11',\n",
    "        'MI9',\n",
    "        'SV3','SV8','SV11','SV12','SV16','SV17','SV18','SV21',\n",
    "        #'pppa0233',\n",
    "        #'pphi0047','pphi0048',\n",
    "        'TET7']]\n",
    "\n",
    "# view column names \n",
    "print \"column names:\"\n",
    "print list(d.columns.values)\n",
    "print\n",
    "\n",
    "# print example rows\n",
    "\n",
    "print d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Add Demographic Dictionaries for Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create demographic dictionaries to later print readable values, not numeric keys\n",
    "\n",
    "# 'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', PPSTATEN'\n",
    "\n",
    "core_par = {-2: 'Not asked',\n",
    "            -1: 'Refused',\n",
    "             0: 'Not Parent',\n",
    "             1: 'Parent'}\n",
    "\n",
    "ppagecat = { 1: '18-24',\n",
    "             2: '25-34',\n",
    "             3: '35-44',\n",
    "             4: '45-54',\n",
    "             5: '55-64',\n",
    "             6: '65-74',\n",
    "             7: '75+',\n",
    "            99: 'Under 18'}\n",
    "\n",
    "PPETHM = {-2: 'Not asked',\n",
    "          -1: 'REFUSED',\n",
    "           1: 'White',\n",
    "           2: 'Black',\n",
    "           3: 'Other',\n",
    "           4: 'Hispanic',\n",
    "           5: '2+ Races, Non-Hispanic'}\n",
    "\n",
    "PPEDUCAT = {-2: 'Not asked',\n",
    "            -1: 'REFUSED',\n",
    "             1: 'Less than high school',\n",
    "             2: 'High school',\n",
    "             3: 'Some college',\n",
    "             4: 'Bachelor\\'s degree or higher'}\n",
    "\n",
    "PPGENDER = {-2: 'Not asked',\n",
    "            -1: 'REFUSED',\n",
    "             1: 'Male',\n",
    "             2: 'Female'}\n",
    "\n",
    "PPINCCAT = {-2: 'Not asked',\n",
    "            -1: 'Refused',\n",
    "             1: '<$10,000',\n",
    "             2: '$10-49,999',\n",
    "             3: '$50-74,999',\n",
    "             4: '$75,000+'}\n",
    "\n",
    "PPREG4 = {-2: 'Not asked',\n",
    "          -1: 'REFUSED',\n",
    "           1: 'Northeast',\n",
    "           2: 'Midwest',\n",
    "           3: 'South',\n",
    "           4: 'West'}\n",
    "\n",
    "PPSTATEN = { -2: 'Not asked'\n",
    "            ,-1: 'REFUSED'\n",
    "            ,11: 'ME'\n",
    "            ,12: 'NH' \n",
    "            ,13: 'VT' \n",
    "            ,14: 'MA' \n",
    "            ,15: 'RI' \n",
    "            ,16: 'CT' \n",
    "            ,21: 'NY' \n",
    "            ,22: 'NJ' \n",
    "            ,23: 'PA' \n",
    "            ,31: 'OH' \n",
    "            ,32: 'IN'\n",
    "            ,33: 'IL' \n",
    "            ,34: 'MI' \n",
    "            ,35: 'WI' \n",
    "            ,41: 'MN' \n",
    "            ,42: 'IA' \n",
    "            ,43: 'MO' \n",
    "            ,44: 'ND' \n",
    "            ,45: 'SD' \n",
    "            ,46: 'NE' \n",
    "            ,47: 'KS' \n",
    "            ,51: 'DE' \n",
    "            ,52: 'MD' \n",
    "            ,53: 'DC' \n",
    "            ,54: 'VA' \n",
    "            ,55: 'WV' \n",
    "            ,56: 'NC' \n",
    "            ,57: 'SC' \n",
    "            ,58: 'GA' \n",
    "            ,59: 'FL' \n",
    "            ,61: 'KY' \n",
    "            ,62: 'TN' \n",
    "            ,63: 'AL' \n",
    "            ,64: 'MS' \n",
    "            ,71: 'AR' \n",
    "            ,72: 'LA' \n",
    "            ,73: 'OK' \n",
    "            ,74: 'TX' \n",
    "            ,81: 'MT' \n",
    "            ,82: 'ID' \n",
    "            ,83: 'WY' \n",
    "            ,84: 'CO'\n",
    "            ,85: 'NM' \n",
    "            ,86: 'AZ' \n",
    "            ,87: 'UT' \n",
    "            ,88: 'NV' \n",
    "            ,91: 'WA' \n",
    "            ,92: 'OR' \n",
    "            ,93: 'CA' \n",
    "            ,94: 'AK' \n",
    "            ,95: 'HI' \n",
    "            ,96: 'AS' \n",
    "            ,97: 'GU' \n",
    "            ,98: 'PR' \n",
    "            ,99: 'VI'}\n",
    "\n",
    "print \"before update:\"\n",
    "print d['core_par'][:5] \n",
    "print\n",
    "\n",
    "# apply dictionaries to their corresponding columns\n",
    "\n",
    "d['core_par'] = d['core_par'].apply(lambda x: core_par[x])\n",
    "d['ppagecat'] = d['ppagecat'].apply(lambda x: ppagecat[x])\n",
    "d['PPETHM'] = d['PPETHM'].apply(lambda x: PPETHM[x])\n",
    "d['PPEDUCAT'] = d['PPEDUCAT'].apply(lambda x: PPEDUCAT[x])\n",
    "d['PPGENDER'] = d['PPGENDER'].apply(lambda x: PPGENDER[x])\n",
    "d['PPINCCAT'] = d['PPINCCAT'].apply(lambda x: PPINCCAT[x])\n",
    "d['PPREG4'] = d['PPREG4'].apply(lambda x: PPREG4[x])\n",
    "d['PPSTATEN'] = d['PPSTATEN'].apply(lambda x: PPSTATEN[x])\n",
    "\n",
    "# quality check one case\n",
    "\n",
    "print \"after update:\"\n",
    "print d['core_par'][:5] \n",
    "\n",
    "'''\n",
    "print d['ppagecat']\n",
    "print d['PPETHM'] \n",
    "print d['PPEDUCAT'] \n",
    "print d['PPGENDER'] \n",
    "print d['PPINCCAT']\n",
    "print d['PPREG4']\n",
    "print d['PPSTATEN']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Recode Non-Demographic Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-41ebdbb29e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# replace negative values with NaN (not a number)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "# document scales of non-demographic columns of interest\n",
    "\n",
    "'''\n",
    "# columns with ascending response options (e.g., 1 = strongly agree)\n",
    "'EPQ1' (1-7)\n",
    "'I10' (1-5)\n",
    "'L1' (1-7)\n",
    "'SV' (1-7)\n",
    "'pphi0047','pphi0048' (1-4)\n",
    "\n",
    "# columns with descending response options (e.g., 7 = strongly disagree)\n",
    "'DPES11' (1-7)\n",
    "'IS1','IS6','IS8' (1-5)\n",
    "'MI9' (1-7)\n",
    "'TET' (1-5)\n",
    "\n",
    "# columns that asks respondent to rank top categories\n",
    "'MOPS11','MOPS12'\n",
    "'''\n",
    "\n",
    "# replace negative values with NaN (not a number)\n",
    "\n",
    "for i in range(9, d.shape[1]):\n",
    "    \n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(-1,np.NaN)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(-2,np.NaN)\n",
    "\n",
    "# define function that, for example, transforms survey value from 1 to 7, 7 to 1, etc., \n",
    "# to normalize values across survey questions, where values 1 and 2 are always a yes-type response\n",
    "\n",
    "# x refers to column, and xmax refers to the max possible value per the survey codebook\n",
    "\n",
    "def reverse(x, xmax):\n",
    "    x = xmax + 1 - x\n",
    "    return x \n",
    "    \n",
    "# invoke reverse function on appropriate columns\n",
    "\n",
    "d.DPES11 = reverse(d.DPES11, 7)\n",
    "d.IS1    = reverse(d.IS1, 5)\n",
    "d.IS6    = reverse(d.IS6, 5)\n",
    "d.IS8    = reverse(d.IS8, 5)\n",
    "d.MI9    = reverse(d.MI9, 7)\n",
    "d.TET7   = reverse(d.TET7, 5)\n",
    "\n",
    "# store dataframe headers in an object to call this object in print statement later\n",
    "\n",
    "headers = d.columns.values.tolist()\n",
    "\n",
    "# loop through non-demographic columns, which start a index 9\n",
    "\n",
    "for i in range(9, d.shape[1]):\n",
    "    \n",
    "    print \"before recode:\"\n",
    "    print d[d.columns[i]][:5]\n",
    "    print\n",
    "    \n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(2,1)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(3,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(4,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(5,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(6,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(7,0)\n",
    "    \n",
    "    print \"after recode:\"\n",
    "    print (d[d.columns[i]][:5])\n",
    "    print\n",
    "\n",
    "print d.describe()\n",
    "\n",
    "'''\n",
    "# comment out subset that removes missing values, and instead hold off until cell below to\n",
    "# instead invoke on a column-by-column basis and thereby preserve more sample size\n",
    "\n",
    "d = d.dropna(subset = \n",
    "      [ 'weight',\n",
    "        'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', 'PPSTATEN',\n",
    "        'DPES11',\n",
    "        'EPQ1',\n",
    "        'I10',\n",
    "        'IS1','IS6','IS8',\n",
    "        'L1','L4','L9','L11',\n",
    "        'MI9',\n",
    "        'SV3','SV8','SV11','SV12','SV16','SV17','SV18','SV21',\n",
    "        #'pppa0233',\n",
    "        #'pphi0047','pphi0048',\n",
    "        'TET7'])\n",
    "        \n",
    "print d.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Weighted averages on dummy data (temp section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "\n",
      "dataframe:\n",
      "    c1   c2\n",
      "1  0.7  0.5\n",
      "2  0.1  0.5\n",
      "\n",
      "(0,0): 0.7\n",
      "(0,1): 0.5\n",
      "(1,0): 0.1\n",
      "(1,1): 0.5\n",
      "\n",
      "Manual weighted avg: weighted sum / sum of weights = (0.7*0.5 + 0.1*.05) / (0.5 + 0.5) = 0.4\n",
      "Python weighted avg: 0.4\n"
     ]
    }
   ],
   "source": [
    "# explore basic example of weighted column, not row, averages in Python\n",
    "\n",
    "c1 = [.9, .1]\n",
    "c2 = [.5, .5]\n",
    "\n",
    "test = pd.DataFrame({'c1': [.7, .1],\n",
    "                     'c2': [.5, .5]},\n",
    "                    index = [1, 2])\n",
    "\n",
    "print \"shape:\", test.shape\n",
    "print\n",
    "print \"dataframe:\"\n",
    "print test[:]\n",
    "print \n",
    "\n",
    "print \"(0,0):\", test.iloc[0][0]\n",
    "print \"(0,1):\", test.iloc[0][1]\n",
    "print \"(1,0):\", test.iloc[1][0]\n",
    "print \"(1,1):\", test.iloc[1][1]\n",
    "print \n",
    "\n",
    "# http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ma.average.html#numpy.ma.average\n",
    "# purposely place the c2 as the weights, to calculate correctly\n",
    "\n",
    "print \"Manual weighted avg: weighted sum / sum of weights = (0.7*0.5 + 0.1*.05) / (0.5 + 0.5) = 0.4\"\n",
    "print \"Python weighted avg:\", round(np.average(a=test['c1'], weights=test['c2']),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Export Weighted Averages, Grouped by Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d208ae10d900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# http://www.atlas.illinois.edu/support/stats/resources/spss/create-post-stratification-weights-for-survery-analysis.pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DPES11_wt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDPES11\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PPREG4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DPES11'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DPES11_wt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "# explore weights further, now on some actual survey data \n",
    "\n",
    "# multiple column by post-stratification weight, which is important so the sample better reflects the population\n",
    "# http://www.atlas.illinois.edu/support/stats/resources/spss/create-post-stratification-weights-for-survery-analysis.pdf\n",
    "\n",
    "d['DPES11_wt'] = d.DPES11 * d.weight\n",
    "print d.loc[:, ['weight','PPREG4','DPES11','DPES11_wt']][:10]\n",
    "print\n",
    "\n",
    "# calculate step-by-step weighted average (which overlooks if NaN exists)\n",
    "print \"1:\", d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.DPES11*x.weight))\n",
    "print\n",
    "print \"1:\", d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.weight))\n",
    "print\n",
    "print \"1:\", d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.DPES11*x.weight) / np.sum(x.weight))\n",
    "print\n",
    "\n",
    "'''\n",
    "#temp = pd.DataFrame(d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.DPES11*x.weight) / np.sum(x.weight)))\n",
    "#temp.rename(columns = {0:'Weighted Pct'}, inplace = True)\n",
    "\n",
    "# calculate with np.average function (which does not overlook if NaN exists) \n",
    "# option is to use mask function with np.ma.average, but avoid that after trial\n",
    "# http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ma.masked_invalid.html\n",
    "\n",
    "# print \"2:\", d.groupby(['PPREG4','PPGENDER']).apply(lambda x: np.average(a=x['DPES11'], weights=x['weight'], returned=True))\n",
    "'''\n",
    "\n",
    "# create wt_avg function that \n",
    "# 1) takes two demographic columns and a list of non-demographic columns,\n",
    "# 2) scrolls through each non-demographic column to calculate the weighted average,\n",
    "# 3) and exports data to one csv file per non-demographic column\n",
    "\n",
    "def wt_avg(demo1, demo2, cnames):\n",
    "    \n",
    "    for cname in cnames:\n",
    "        \n",
    "        # subset given column to remove its rows with missing values, otherwise np.average runs into issues\n",
    "        # http://stackoverflow.com/questions/13413590/how-to-drop-rows-of-pandas-dataframe-whose-value-of-certain-column-is-nan\n",
    "        temp = d.dropna(subset = [cname])\n",
    "        \n",
    "        # take the groupby weighted average of given column\n",
    "        temp = temp.groupby([demo1, demo2]).apply(lambda x: np.average(a=x[cname], weights=x['weight']))\n",
    "        print temp\n",
    "        print\n",
    "        \n",
    "        # export results to csv in format for D3.js graphs\n",
    "        temp.to_csv('/Users/dschan/Downloads/UCB-MIDS-W209/Interactive/files_for_D3/' + \n",
    "            demo1 + \"_\" + demo2 + \"_\" + cname + '.csv', header=True, index=True)\n",
    "\n",
    "# invoke wt_avg function\n",
    "\n",
    "wt_avg('PPREG4', \n",
    "       'PPGENDER',\n",
    "       ['DPES11', 'EPQ1', 'I10', 'IS1','IS6','IS8', 'L1','L4','L9','L11', 'MI9', \n",
    "        'SV3','SV8','SV11','SV12','SV16','SV17','SV18','SV21','TET7'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
