{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data from Duke University and GfK's \"Measuring Morality\" project \n",
    "\n",
    "- **Goal**: Place data in format for interactive visualizations in D3.js\n",
    "\n",
    "- **Dataset Source:** http://kenan.ethics.duke.edu/attitudes/resources/measuring-morality/\n",
    "- **Codebook Source:** http://kenan.ethics.duke.edu/attitudes/files/2012/08/KN-Morality-Survey-Technical-Report.pdf\n",
    "\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Explore and Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "shape: 1519\n",
      "\n",
      "column names:\n",
      "['weight', 'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', 'PPSTATEN', 'DPES11', 'EPQ1', 'I10', 'IS1', 'IS6', 'IS8', 'L1', 'L4', 'L9', 'L11', 'MI9', 'SV3', 'SV8', 'SV11', 'SV12', 'SV16', 'SV17', 'SV18', 'SV21', 'TET7']\n",
      "\n",
      "   weight  core_par  ppagecat  PPETHM  PPEDUCAT  PPGENDER  PPINCCAT  PPREG4  \\\n",
      "0    1.05         0         6       1         4         2         3       4   \n",
      "1    2.60         0         2       1         3         1         3       2   \n",
      "2    0.69         1         2       4         2         2         2       4   \n",
      "3    1.74         1         3       1         4         2         4       3   \n",
      "4    2.43         0         3       1         3         2         4       4   \n",
      "\n",
      "   PPSTATEN  DPES11  ...   MI9  SV3  SV8  SV11  SV12  SV16  SV17  SV18  SV21  \\\n",
      "0        81       5  ...     4    4    4     2    -1     1     3     3     4   \n",
      "1        47       5  ...     7    2    1     2     1     5     2     2     2   \n",
      "2        91       3  ...     4    1    5     4     2     1     1     1     5   \n",
      "3        56       6  ...     5    1    2     2     4     2     3     4     4   \n",
      "4        88       6  ...     4    3    3     4     4     3     3     3     3   \n",
      "\n",
      "   TET7  \n",
      "0     3  \n",
      "1     4  \n",
      "2     2  \n",
      "3     5  \n",
      "4     3  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# read csv data as pandas dataframe\n",
    "\n",
    "d = pd.read_csv('/Users/dschan/Downloads/UCB-MIDS-W209/Interactive/MMdata_merged.csv')\n",
    "\n",
    "# check data type and shape\n",
    "\n",
    "print type(d)\n",
    "print \"shape:\", d.shape[0]\n",
    "print\n",
    "\n",
    "# select specific columns: weight column, demographic columns, and moral-related columns\n",
    "\n",
    "d = d[[ 'weight',\n",
    "        'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', 'PPSTATEN',\n",
    "        'DPES11',\n",
    "        'EPQ1',\n",
    "        'I10',\n",
    "        'IS1','IS6','IS8',\n",
    "        'L1','L4','L9','L11',\n",
    "        'MI9',\n",
    "        'SV3','SV8','SV11','SV12','SV16','SV17','SV18','SV21',\n",
    "        #'pppa0233',\n",
    "        #'pphi0047','pphi0048',\n",
    "        'TET7']]\n",
    "\n",
    "# view column names \n",
    "print \"column names:\"\n",
    "print list(d.columns.values)\n",
    "print\n",
    "\n",
    "# print example rows\n",
    "\n",
    "print d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Add Demographic Dictionaries for Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before update:\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: core_par, dtype: int64\n",
      "\n",
      "after update:\n",
      "0    Not Parent\n",
      "1    Not Parent\n",
      "2        Parent\n",
      "3        Parent\n",
      "4    Not Parent\n",
      "Name: core_par, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint d['ppagecat']\\nprint d['PPETHM'] \\nprint d['PPEDUCAT'] \\nprint d['PPGENDER'] \\nprint d['PPINCCAT']\\nprint d['PPREG4']\\nprint d['PPSTATEN']\\n\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create demographic dictionaries to later print readable values, not numeric keys\n",
    "\n",
    "# 'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', PPSTATEN'\n",
    "\n",
    "core_par = {-2: 'Not asked',\n",
    "            -1: 'Refused',\n",
    "             0: 'Not Parent',\n",
    "             1: 'Parent'}\n",
    "\n",
    "ppagecat = { 1: '18-24',\n",
    "             2: '25-34',\n",
    "             3: '35-44',\n",
    "             4: '45-54',\n",
    "             5: '55-64',\n",
    "             6: '65-74',\n",
    "             7: '75+',\n",
    "            99: 'Under 18'}\n",
    "\n",
    "PPETHM = {-2: 'Not asked',\n",
    "          -1: 'REFUSED',\n",
    "           1: 'White',\n",
    "           2: 'Black',\n",
    "           3: 'Other',\n",
    "           4: 'Hispanic',\n",
    "           5: '2+ Races, Non-Hispanic'}\n",
    "\n",
    "PPEDUCAT = {-2: 'Not asked',\n",
    "            -1: 'REFUSED',\n",
    "             1: 'Less than high school',\n",
    "             2: 'High school',\n",
    "             3: 'Some college',\n",
    "             4: 'Bachelor\\'s degree or higher'}\n",
    "\n",
    "PPGENDER = {-2: 'Not asked',\n",
    "            -1: 'REFUSED',\n",
    "             1: 'Male',\n",
    "             2: 'Female'}\n",
    "\n",
    "PPINCCAT = {-2: 'Not asked',\n",
    "            -1: 'Refused',\n",
    "             1: '<$10,000',\n",
    "             2: '$10-49,999',\n",
    "             3: '$50-74,999',\n",
    "             4: '$75,000+'}\n",
    "\n",
    "PPREG4 = {-2: 'Not asked',\n",
    "          -1: 'REFUSED',\n",
    "           1: 'Northeast',\n",
    "           2: 'Midwest',\n",
    "           3: 'South',\n",
    "           4: 'West'}\n",
    "\n",
    "PPSTATEN = { -2: 'Not asked'\n",
    "            ,-1: 'REFUSED'\n",
    "            ,11: 'ME'\n",
    "            ,12: 'NH' \n",
    "            ,13: 'VT' \n",
    "            ,14: 'MA' \n",
    "            ,15: 'RI' \n",
    "            ,16: 'CT' \n",
    "            ,21: 'NY' \n",
    "            ,22: 'NJ' \n",
    "            ,23: 'PA' \n",
    "            ,31: 'OH' \n",
    "            ,32: 'IN'\n",
    "            ,33: 'IL' \n",
    "            ,34: 'MI' \n",
    "            ,35: 'WI' \n",
    "            ,41: 'MN' \n",
    "            ,42: 'IA' \n",
    "            ,43: 'MO' \n",
    "            ,44: 'ND' \n",
    "            ,45: 'SD' \n",
    "            ,46: 'NE' \n",
    "            ,47: 'KS' \n",
    "            ,51: 'DE' \n",
    "            ,52: 'MD' \n",
    "            ,53: 'DC' \n",
    "            ,54: 'VA' \n",
    "            ,55: 'WV' \n",
    "            ,56: 'NC' \n",
    "            ,57: 'SC' \n",
    "            ,58: 'GA' \n",
    "            ,59: 'FL' \n",
    "            ,61: 'KY' \n",
    "            ,62: 'TN' \n",
    "            ,63: 'AL' \n",
    "            ,64: 'MS' \n",
    "            ,71: 'AR' \n",
    "            ,72: 'LA' \n",
    "            ,73: 'OK' \n",
    "            ,74: 'TX' \n",
    "            ,81: 'MT' \n",
    "            ,82: 'ID' \n",
    "            ,83: 'WY' \n",
    "            ,84: 'CO'\n",
    "            ,85: 'NM' \n",
    "            ,86: 'AZ' \n",
    "            ,87: 'UT' \n",
    "            ,88: 'NV' \n",
    "            ,91: 'WA' \n",
    "            ,92: 'OR' \n",
    "            ,93: 'CA' \n",
    "            ,94: 'AK' \n",
    "            ,95: 'HI' \n",
    "            ,96: 'AS' \n",
    "            ,97: 'GU' \n",
    "            ,98: 'PR' \n",
    "            ,99: 'VI'}\n",
    "\n",
    "print \"before update:\"\n",
    "print d['core_par'][:5] \n",
    "print\n",
    "\n",
    "# apply dictionaries to their corresponding columns\n",
    "\n",
    "d['core_par'] = d['core_par'].apply(lambda x: core_par[x])\n",
    "d['ppagecat'] = d['ppagecat'].apply(lambda x: ppagecat[x])\n",
    "d['PPETHM'] = d['PPETHM'].apply(lambda x: PPETHM[x])\n",
    "d['PPEDUCAT'] = d['PPEDUCAT'].apply(lambda x: PPEDUCAT[x])\n",
    "d['PPGENDER'] = d['PPGENDER'].apply(lambda x: PPGENDER[x])\n",
    "d['PPINCCAT'] = d['PPINCCAT'].apply(lambda x: PPINCCAT[x])\n",
    "d['PPREG4'] = d['PPREG4'].apply(lambda x: PPREG4[x])\n",
    "d['PPSTATEN'] = d['PPSTATEN'].apply(lambda x: PPSTATEN[x])\n",
    "\n",
    "# quality check one case\n",
    "\n",
    "print \"after update:\"\n",
    "print d['core_par'][:5] \n",
    "\n",
    "'''\n",
    "print d['ppagecat']\n",
    "print d['PPETHM'] \n",
    "print d['PPEDUCAT'] \n",
    "print d['PPGENDER'] \n",
    "print d['PPINCCAT']\n",
    "print d['PPREG4']\n",
    "print d['PPSTATEN']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Recode Non-Demographic Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before recode:\n",
      "0    3\n",
      "1    3\n",
      "2    5\n",
      "3    2\n",
      "4    2\n",
      "Name: DPES11, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: DPES11, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    3\n",
      "1    1\n",
      "2    4\n",
      "3    5\n",
      "4    4\n",
      "Name: EPQ1, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: EPQ1, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    3\n",
      "1    4\n",
      "2    3\n",
      "3    3\n",
      "4    3\n",
      "Name: I10, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: I10, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    4\n",
      "1    5\n",
      "2    5\n",
      "3    5\n",
      "4    3\n",
      "Name: IS1, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: IS1, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    3\n",
      "1    2\n",
      "2    2\n",
      "3    3\n",
      "4    3\n",
      "Name: IS6, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: IS6, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    4\n",
      "1    2\n",
      "2    4\n",
      "3    2\n",
      "4    4\n",
      "Name: IS8, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: IS8, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    3\n",
      "1    6\n",
      "2    6\n",
      "3    4\n",
      "4    4\n",
      "Name: L1, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: L1, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    5\n",
      "1    7\n",
      "2    4\n",
      "3    5\n",
      "4    5\n",
      "Name: L4, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: L4, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    4\n",
      "1    7\n",
      "2    5\n",
      "3    7\n",
      "4    6\n",
      "Name: L9, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: L9, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    5\n",
      "1    6\n",
      "2    5\n",
      "3    6\n",
      "4    5\n",
      "Name: L11, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: L11, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    4\n",
      "1    1\n",
      "2    4\n",
      "3    3\n",
      "4    4\n",
      "Name: MI9, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: MI9, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    4\n",
      "1    2\n",
      "2    1\n",
      "3    1\n",
      "4    3\n",
      "Name: SV3, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: SV3, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    4\n",
      "1    1\n",
      "2    5\n",
      "3    2\n",
      "4    3\n",
      "Name: SV8, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: SV8, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    2\n",
      "1    2\n",
      "2    4\n",
      "3    2\n",
      "4    4\n",
      "Name: SV11, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: SV11, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0   NaN\n",
      "1     1\n",
      "2     2\n",
      "3     4\n",
      "4     4\n",
      "Name: SV12, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0   NaN\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     0\n",
      "Name: SV12, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    1\n",
      "1    5\n",
      "2    1\n",
      "3    2\n",
      "4    3\n",
      "Name: SV16, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: SV16, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    3\n",
      "1    2\n",
      "2    1\n",
      "3    3\n",
      "4    3\n",
      "Name: SV17, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: SV17, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    3\n",
      "1    2\n",
      "2    1\n",
      "3    4\n",
      "4    3\n",
      "Name: SV18, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: SV18, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    4\n",
      "1    2\n",
      "2    5\n",
      "3    4\n",
      "4    3\n",
      "Name: SV21, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: SV21, dtype: float64\n",
      "\n",
      "before recode:\n",
      "0    3\n",
      "1    2\n",
      "2    4\n",
      "3    1\n",
      "4    3\n",
      "Name: TET7, dtype: float64\n",
      "\n",
      "after recode:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: TET7, dtype: float64\n",
      "\n",
      "            weight       DPES11         EPQ1          I10          IS1  \\\n",
      "count  1519.000000  1495.000000  1505.000000  1505.000000  1507.000000   \n",
      "mean      1.000112     0.501672     0.259801     0.497010     0.051095   \n",
      "std       0.734256     0.500165     0.438671     0.500157     0.220264   \n",
      "min       0.140000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.430000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.770000     1.000000     0.000000     0.000000     0.000000   \n",
      "75%       1.380000     1.000000     1.000000     1.000000     0.000000   \n",
      "max       3.560000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "               IS6          IS8           L1           L4           L9  \\\n",
      "count  1505.000000  1505.000000  1503.000000  1503.000000  1499.000000   \n",
      "mean      0.712292     0.143522     0.079175     0.067199     0.018679   \n",
      "std       0.452845     0.350721     0.270102     0.250450     0.135434   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "          ...               MI9          SV3          SV8         SV11  \\\n",
      "count     ...       1499.000000  1502.000000  1498.000000  1494.000000   \n",
      "mean      ...          0.316211     0.633822     0.537383     0.633199   \n",
      "std       ...          0.465151     0.481920     0.498767     0.482093   \n",
      "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "50%       ...          0.000000     1.000000     1.000000     1.000000   \n",
      "75%       ...          1.000000     1.000000     1.000000     1.000000   \n",
      "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "             SV12         SV16         SV17         SV18         SV21  \\\n",
      "count  1492.00000  1496.000000  1504.000000  1493.000000  1494.000000   \n",
      "mean      0.58311     0.467246     0.230718     0.672472     0.325971   \n",
      "std       0.49321     0.499093     0.421432     0.469469     0.468893   \n",
      "min       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       1.00000     0.000000     0.000000     1.000000     0.000000   \n",
      "75%       1.00000     1.000000     0.000000     1.000000     1.000000   \n",
      "max       1.00000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              TET7  \n",
      "count  1502.000000  \n",
      "mean      0.701065  \n",
      "std       0.457944  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       1.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# comment out subset that removes missing values, and instead hold off until cell below to\\n# instead invoke on a column-by-column basis and thereby preserve more sample size\\n\\nd = d.dropna(subset = \\n      [ 'weight',\\n        'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', 'PPSTATEN',\\n        'DPES11',\\n        'EPQ1',\\n        'I10',\\n        'IS1','IS6','IS8',\\n        'L1','L4','L9','L11',\\n        'MI9',\\n        'SV3','SV8','SV11','SV12','SV16','SV17','SV18','SV21',\\n        #'pppa0233',\\n        #'pphi0047','pphi0048',\\n        'TET7'])\\n        \\nprint d.shape\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document scales of non-demographic columns of interest\n",
    "\n",
    "'''\n",
    "# columns with ascending response options (e.g., 1 = strongly agree)\n",
    "'EPQ1' (1-7)\n",
    "'I10' (1-5)\n",
    "'L1' (1-7)\n",
    "'SV' (1-7)\n",
    "'pphi0047','pphi0048' (1-4)\n",
    "\n",
    "# columns with descending response options (e.g., 7 = strongly disagree)\n",
    "'DPES11' (1-7)\n",
    "'IS1','IS6','IS8' (1-5)\n",
    "'MI9' (1-7)\n",
    "'TET' (1-5)\n",
    "\n",
    "# columns that asks respondent to rank top categories\n",
    "'MOPS11','MOPS12'\n",
    "'''\n",
    "\n",
    "# replace negative values with NaN (not a number)\n",
    "\n",
    "for i in range(9, d.shape[1]):\n",
    "    \n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(-1,np.NaN)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(-2,np.NaN)\n",
    "\n",
    "# define function that, for example, transforms survey value from 1 to 7, 7 to 1, etc., \n",
    "# to normalize values across survey questions, where values 1 and 2 are always a yes-type response\n",
    "\n",
    "# x refers to column, and xmax refers to the max possible value per the survey codebook\n",
    "\n",
    "def reverse(x, xmax):\n",
    "    x = xmax + 1 - x\n",
    "    return x \n",
    "    \n",
    "# invoke reverse function on appropriate columns\n",
    "\n",
    "d.DPES11 = reverse(d.DPES11, 7)\n",
    "d.IS1    = reverse(d.IS1, 5)\n",
    "d.IS6    = reverse(d.IS6, 5)\n",
    "d.IS8    = reverse(d.IS8, 5)\n",
    "d.MI9    = reverse(d.MI9, 7)\n",
    "d.TET7   = reverse(d.TET7, 5)\n",
    "\n",
    "# store dataframe headers in an object to call this object in print statement later\n",
    "\n",
    "headers = d.columns.values.tolist()\n",
    "\n",
    "# loop through non-demographic columns, which start a index 9\n",
    "\n",
    "for i in range(9, d.shape[1]):\n",
    "    \n",
    "    print \"before recode:\"\n",
    "    print d[d.columns[i]][:5]\n",
    "    print\n",
    "    \n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(2,1)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(3,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(4,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(5,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(6,0)\n",
    "    d[d.columns[i]] = d[d.columns[i]].replace(7,0)\n",
    "    \n",
    "    print \"after recode:\"\n",
    "    print (d[d.columns[i]][:5])\n",
    "    print\n",
    "\n",
    "print d.describe()\n",
    "\n",
    "'''\n",
    "# comment out subset that removes missing values, and instead hold off until cell below to\n",
    "# instead invoke on a column-by-column basis and thereby preserve more sample size\n",
    "\n",
    "d = d.dropna(subset = \n",
    "      [ 'weight',\n",
    "        'core_par', 'ppagecat', 'PPETHM', 'PPEDUCAT', 'PPGENDER', 'PPINCCAT', 'PPREG4', 'PPSTATEN',\n",
    "        'DPES11',\n",
    "        'EPQ1',\n",
    "        'I10',\n",
    "        'IS1','IS6','IS8',\n",
    "        'L1','L4','L9','L11',\n",
    "        'MI9',\n",
    "        'SV3','SV8','SV11','SV12','SV16','SV17','SV18','SV21',\n",
    "        #'pppa0233',\n",
    "        #'pphi0047','pphi0048',\n",
    "        'TET7'])\n",
    "        \n",
    "print d.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Weighted averages on dummy data (temp section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "\n",
      "dataframe:\n",
      "    c1   c2\n",
      "1  0.7  0.5\n",
      "2  0.1  0.5\n",
      "\n",
      "(0,0): 0.7\n",
      "(0,1): 0.5\n",
      "(1,0): 0.1\n",
      "(1,1): 0.5\n",
      "\n",
      "Manual weighted avg: weighted sum / sum of weights = (0.7*0.5 + 0.1*.05) / (0.5 + 0.5) = 0.4\n",
      "Python weighted avg: 0.4\n"
     ]
    }
   ],
   "source": [
    "# explore basic example of weighted column, not row, averages in Python\n",
    "\n",
    "c1 = [.9, .1]\n",
    "c2 = [.5, .5]\n",
    "\n",
    "test = pd.DataFrame({'c1': [.7, .1],\n",
    "                     'c2': [.5, .5]},\n",
    "                    index = [1, 2])\n",
    "\n",
    "print \"shape:\", test.shape\n",
    "print\n",
    "print \"dataframe:\"\n",
    "print test[:]\n",
    "print \n",
    "\n",
    "print \"(0,0):\", test.iloc[0][0]\n",
    "print \"(0,1):\", test.iloc[0][1]\n",
    "print \"(1,0):\", test.iloc[1][0]\n",
    "print \"(1,1):\", test.iloc[1][1]\n",
    "print \n",
    "\n",
    "# http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ma.average.html#numpy.ma.average\n",
    "# purposely place the c2 as the weights, to calculate correctly\n",
    "\n",
    "print \"Manual weighted avg: weighted sum / sum of weights = (0.7*0.5 + 0.1*.05) / (0.5 + 0.5) = 0.4\"\n",
    "print \"Python weighted avg:\", round(np.average(a=test['c1'], weights=test['c2']),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Export Weighted Averages, Grouped by Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weight     PPREG4  DPES11  DPES11_wt\n",
      "0    1.05       West       0       0.00\n",
      "1    2.60    Midwest       0       0.00\n",
      "2    0.69       West       0       0.00\n",
      "3    1.74      South       1       1.74\n",
      "4    2.43       West       1       2.43\n",
      "5    2.72    Midwest       0       0.00\n",
      "6    0.42    Midwest       0       0.00\n",
      "7    0.29      South       1       0.29\n",
      "8    0.76  Northeast       0       0.00\n",
      "9    1.00       West       1       1.00\n",
      "\n",
      "1: PPREG4     PPGENDER\n",
      "Midwest    Female       97.98\n",
      "           Male         61.31\n",
      "Northeast  Female       81.88\n",
      "           Male         51.69\n",
      "South      Female      163.00\n",
      "           Male        118.41\n",
      "West       Female       93.03\n",
      "           Male         69.19\n",
      "dtype: float64\n",
      "\n",
      "1: PPREG4     PPGENDER\n",
      "Midwest    Female      169.70\n",
      "           Male        157.50\n",
      "Northeast  Female      150.84\n",
      "           Male        126.96\n",
      "South      Female      287.15\n",
      "           Male        276.32\n",
      "West       Female      179.75\n",
      "           Male        170.95\n",
      "dtype: float64\n",
      "\n",
      "1: PPREG4     PPGENDER\n",
      "Midwest    Female      0.577372\n",
      "           Male        0.389270\n",
      "Northeast  Female      0.542827\n",
      "           Male        0.407136\n",
      "South      Female      0.567648\n",
      "           Male        0.428525\n",
      "West       Female      0.517552\n",
      "           Male        0.404738\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.583527\n",
      "           Male        0.390162\n",
      "Northeast  Female      0.552758\n",
      "           Male        0.410238\n",
      "South      Female      0.573984\n",
      "           Male        0.433704\n",
      "West       Female      0.556000\n",
      "           Male        0.408442\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.229051\n",
      "           Male        0.268891\n",
      "Northeast  Female      0.250017\n",
      "           Male        0.265911\n",
      "South      Female      0.256776\n",
      "           Male        0.251727\n",
      "West       Female      0.300631\n",
      "           Male        0.278215\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.611653\n",
      "           Male        0.454778\n",
      "Northeast  Female      0.453470\n",
      "           Male        0.367263\n",
      "South      Female      0.622016\n",
      "           Male        0.428304\n",
      "West       Female      0.463243\n",
      "           Male        0.373072\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.019962\n",
      "           Male        0.073487\n",
      "Northeast  Female      0.054474\n",
      "           Male        0.077190\n",
      "South      Female      0.043469\n",
      "           Male        0.067288\n",
      "West       Female      0.032355\n",
      "           Male        0.091434\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.786766\n",
      "           Male        0.728254\n",
      "Northeast  Female      0.640496\n",
      "           Male        0.640359\n",
      "South      Female      0.729892\n",
      "           Male        0.656530\n",
      "West       Female      0.724759\n",
      "           Male        0.641322\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.140837\n",
      "           Male        0.189591\n",
      "Northeast  Female      0.158373\n",
      "           Male        0.165249\n",
      "South      Female      0.098580\n",
      "           Male        0.179340\n",
      "West       Female      0.102706\n",
      "           Male        0.199428\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.064997\n",
      "           Male        0.089714\n",
      "Northeast  Female      0.046652\n",
      "           Male        0.114367\n",
      "South      Female      0.053312\n",
      "           Male        0.077442\n",
      "West       Female      0.076047\n",
      "           Male        0.057652\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.050867\n",
      "           Male        0.097016\n",
      "Northeast  Female      0.077369\n",
      "           Male        0.070495\n",
      "South      Female      0.030495\n",
      "           Male        0.087357\n",
      "West       Female      0.056493\n",
      "           Male        0.068749\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.056373\n",
      "           Male        0.034276\n",
      "Northeast  Female      0.013624\n",
      "           Male        0.028601\n",
      "South      Female      0.000000\n",
      "           Male        0.016790\n",
      "West       Female      0.012512\n",
      "           Male        0.009769\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.047559\n",
      "           Male        0.047458\n",
      "Northeast  Female      0.025786\n",
      "           Male        0.026741\n",
      "South      Female      0.017184\n",
      "           Male        0.012443\n",
      "West       Female      0.018298\n",
      "           Male        0.021351\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.390370\n",
      "           Male        0.276448\n",
      "Northeast  Female      0.354791\n",
      "           Male        0.341052\n",
      "South      Female      0.410364\n",
      "           Male        0.228071\n",
      "West       Female      0.308137\n",
      "           Male        0.240183\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.704853\n",
      "           Male        0.529143\n",
      "Northeast  Female      0.671807\n",
      "           Male        0.580892\n",
      "South      Female      0.719976\n",
      "           Male        0.577941\n",
      "West       Female      0.613913\n",
      "           Male        0.569894\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.531011\n",
      "           Male        0.450766\n",
      "Northeast  Female      0.568165\n",
      "           Male        0.456207\n",
      "South      Female      0.607553\n",
      "           Male        0.425026\n",
      "West       Female      0.564496\n",
      "           Male        0.505136\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.600390\n",
      "           Male        0.646655\n",
      "Northeast  Female      0.572195\n",
      "           Male        0.714263\n",
      "South      Female      0.650965\n",
      "           Male        0.638780\n",
      "West       Female      0.578841\n",
      "           Male        0.632883\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.702655\n",
      "           Male        0.506159\n",
      "Northeast  Female      0.717499\n",
      "           Male        0.449432\n",
      "South      Female      0.684362\n",
      "           Male        0.468767\n",
      "West       Female      0.539272\n",
      "           Male        0.478121\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.491158\n",
      "           Male        0.441263\n",
      "Northeast  Female      0.517476\n",
      "           Male        0.397369\n",
      "South      Female      0.508009\n",
      "           Male        0.438626\n",
      "West       Female      0.396615\n",
      "           Male        0.387873\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.209036\n",
      "           Male        0.271493\n",
      "Northeast  Female      0.229941\n",
      "           Male        0.272290\n",
      "South      Female      0.247345\n",
      "           Male        0.212427\n",
      "West       Female      0.203527\n",
      "           Male        0.242090\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.744964\n",
      "           Male        0.659730\n",
      "Northeast  Female      0.772939\n",
      "           Male        0.642055\n",
      "South      Female      0.711345\n",
      "           Male        0.572537\n",
      "West       Female      0.670368\n",
      "           Male        0.624391\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.322807\n",
      "           Male        0.381621\n",
      "Northeast  Female      0.329230\n",
      "           Male        0.475981\n",
      "South      Female      0.360891\n",
      "           Male        0.267896\n",
      "West       Female      0.391173\n",
      "           Male        0.321989\n",
      "dtype: float64\n",
      "\n",
      "PPREG4     PPGENDER\n",
      "Midwest    Female      0.723493\n",
      "           Male        0.718603\n",
      "Northeast  Female      0.754928\n",
      "           Male        0.714871\n",
      "South      Female      0.723328\n",
      "           Male        0.617276\n",
      "West       Female      0.782158\n",
      "           Male        0.612581\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore weights further, now on some actual survey data \n",
    "\n",
    "# multiple column by post-stratification weight, which is important so the sample better reflects the population\n",
    "# http://www.atlas.illinois.edu/support/stats/resources/spss/create-post-stratification-weights-for-survery-analysis.pdf\n",
    "\n",
    "d['DPES11_wt'] = d.DPES11 * d.weight\n",
    "print d.loc[:, ['weight','PPREG4','DPES11','DPES11_wt']][:10]\n",
    "print\n",
    "\n",
    "# calculate step-by-step weighted average (which overlooks if NaN exists)\n",
    "print \"1:\", d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.DPES11*x.weight))\n",
    "print\n",
    "print \"1:\", d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.weight))\n",
    "print\n",
    "print \"1:\", d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.DPES11*x.weight) / np.sum(x.weight))\n",
    "print\n",
    "\n",
    "'''\n",
    "#temp = pd.DataFrame(d.groupby(['PPREG4', 'PPGENDER']).apply(lambda x: np.sum(x.DPES11*x.weight) / np.sum(x.weight)))\n",
    "#temp.rename(columns = {0:'Weighted Pct'}, inplace = True)\n",
    "\n",
    "# calculate with np.average function (which does not overlook if NaN exists) \n",
    "# option is to use mask function with np.ma.average, but avoid that after trial\n",
    "# http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ma.masked_invalid.html\n",
    "\n",
    "# print \"2:\", d.groupby(['PPREG4','PPGENDER']).apply(lambda x: np.average(a=x['DPES11'], weights=x['weight'], returned=True))\n",
    "'''\n",
    "\n",
    "# create wt_avg function that \n",
    "# 1) takes two demographic columns and a list of non-demographic columns,\n",
    "# 2) scrolls through each non-demographic column to calculate the weighted average,\n",
    "# 3) and exports data to one csv file per non-demographic column\n",
    "\n",
    "def wt_avg(demo1, demo2, cnames):\n",
    "    \n",
    "    for cname in cnames:\n",
    "        \n",
    "        # subset given column to remove its rows with missing values, otherwise np.average runs into issues\n",
    "        # http://stackoverflow.com/questions/13413590/how-to-drop-rows-of-pandas-dataframe-whose-value-of-certain-column-is-nan\n",
    "        temp = d.dropna(subset = [cname])\n",
    "        \n",
    "        # take the groupby weighted average of given column\n",
    "        temp = temp.groupby([demo1, demo2]).apply(lambda x: np.average(a=x[cname], weights=x['weight']))\n",
    "        print temp\n",
    "        print\n",
    "        \n",
    "        # export results to csv in format for D3.js graphs\n",
    "        temp.to_csv('/Users/dschan/Downloads/UCB-MIDS-W209/Interactive/files_for_D3/' + \n",
    "            demo1 + \"_\" + demo2 + \"_\" + cname + '.csv', header=True, index=True)\n",
    "\n",
    "# invoke wt_avg function\n",
    "\n",
    "wt_avg('PPREG4', \n",
    "       'PPGENDER',\n",
    "       ['DPES11', 'EPQ1', 'I10', 'IS1','IS6','IS8', 'L1','L4','L9','L11', 'MI9', \n",
    "        'SV3','SV8','SV11','SV12','SV16','SV17','SV18','SV21','TET7'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
